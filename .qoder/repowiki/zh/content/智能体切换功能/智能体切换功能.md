# æ™ºèƒ½ä½“åˆ‡æ¢åŠŸèƒ½

<cite>
**æœ¬æ–‡æ¡£å¼•ç”¨çš„æ–‡ä»¶**
- [model-switching-feature.md](file://doc/model-switching-feature.md)
</cite>

## ç›®å½•
1. [æ¦‚è¿°](#æ¦‚è¿°)
2. [æŠ€æœ¯æ ˆ](#æŠ€æœ¯æ ˆ)
3. [æ¶æ„è®¾è®¡](#æ¶æ„è®¾è®¡)
4. [å‰ç«¯ç»„ä»¶æ¶æ„](#å‰ç«¯ç»„ä»¶æ¶æ„)
5. [åç«¯æœåŠ¡è®¾è®¡](#åç«¯æœåŠ¡è®¾è®¡)
6. [ç”¨æˆ·ç•Œé¢è®¾è®¡](#ç”¨æˆ·ç•Œé¢è®¾è®¡)
7. [APIé›†æˆè®¾è®¡](#apié›†æˆè®¾è®¡)
8. [è®¿é—®æ§åˆ¶](#è®¿é—®æ§åˆ¶)
9. [ç›‘æ§å’Œæ—¥å¿—](#ç›‘æ§å’Œæ—¥å¿—)
10. [å®ç°ç»†èŠ‚](#å®ç°ç»†èŠ‚)

## æ¦‚è¿°

æœ¬è®¾è®¡æ–‡æ¡£æè¿°äº†ä¸€ä¸ªä»¿ç…§ ChatGPT å®˜ç½‘çš„æ™ºèƒ½ä½“åˆ‡æ¢åŠŸèƒ½ï¼Œä½¿ç”¨ TypeScript å¼€å‘ã€‚è¯¥åŠŸèƒ½å…è®¸ç”¨æˆ·åœ¨èŠå¤©ç•Œé¢ä¸­åŠ¨æ€åˆ‡æ¢ä¸åŒçš„æ™ºèƒ½ä½“ï¼Œæ¯ä¸ªæ™ºèƒ½ä½“éƒ½æœ‰ç‹¬ç«‹çš„æœåŠ¡ç«¯é…ç½®ï¼ŒåŒ…æ‹¬æ¥å£åœ°å€ã€API Key å’Œæ¨¡å‹åç§°ç­‰ä¿¡æ¯ã€‚

### æ ¸å¿ƒç›®æ ‡
- æä¾›ç±»ä¼¼ ChatGPT å®˜ç½‘çš„ç”¨æˆ·ä½“éªŒ
- æ”¯æŒå¤šæ™ºèƒ½ä½“åŠ¨æ€åˆ‡æ¢
- æœåŠ¡ç«¯ç»Ÿä¸€ç®¡ç†æ™ºèƒ½ä½“é…ç½®
- ä¿æŒå¯¹è¯è¿ç»­æ€§å’Œä¸Šä¸‹æ–‡ç®¡ç†

**Section sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L1-L50)

## æŠ€æœ¯æ ˆ

- **å‰ç«¯**: TypeScript, React/Vue.js, Tailwind CSS
- **åç«¯**: Node.js/Express, TypeScript
- **API æ ‡å‡†**: å…¼å®¹ OpenAI Chat Completions API
- **çŠ¶æ€ç®¡ç†**: Redux/Zustand (React) æˆ– Pinia (Vue)
- **ç½‘ç»œè¯·æ±‚**: Axios/Fetch API
- **ä¸»é¢˜ç³»ç»Ÿ**: CSS Variables, æœ¬åœ°å­˜å‚¨æŒä¹…åŒ–

**Section sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L52-L65)

## æ¶æ„è®¾è®¡

### ç³»ç»Ÿæ¶æ„å›¾

```mermaid
graph TB
subgraph "å‰ç«¯åº”ç”¨"
A[èŠå¤©ç•Œé¢] --> B[æ™ºèƒ½ä½“é€‰æ‹©å™¨]
A --> C[æ¶ˆæ¯ç»„ä»¶]
B --> D[æ™ºèƒ½ä½“çŠ¶æ€ç®¡ç†]
C --> E[æ¶ˆæ¯çŠ¶æ€ç®¡ç†]
end
subgraph "åç«¯æœåŠ¡"
F[æ™ºèƒ½ä½“é…ç½®API] --> G[é…ç½®æ–‡ä»¶ç®¡ç†]
H[èŠå¤©ä»£ç†æœåŠ¡] --> I[æ™ºèƒ½ä½“è·¯ç”±]
I --> J[ç¬¬ä¸‰æ–¹AIæœåŠ¡1]
I --> K[ç¬¬ä¸‰æ–¹AIæœåŠ¡2]
I --> L[ç¬¬ä¸‰æ–¹AIæœåŠ¡N]
end
D --> F
E --> H
style A fill:#e1f5fe
style F fill:#f3e5f5
style H fill:#f3e5f5
```

**Diagram sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L67-L95)

### æ•°æ®æµè®¾è®¡

```mermaid
sequenceDiagram
participant U as ç”¨æˆ·ç•Œé¢
participant AC as æ™ºèƒ½ä½“æ§åˆ¶å™¨
participant CS as èŠå¤©æœåŠ¡
participant AS as æ™ºèƒ½ä½“æœåŠ¡
participant AI as AIæä¾›å•†
U->>AC : é€‰æ‹©æ™ºèƒ½ä½“
AC->>AS : è·å–æ™ºèƒ½ä½“é…ç½®
AS-->>AC : è¿”å›é…ç½®ä¿¡æ¯
AC->>U : æ›´æ–°ç•Œé¢çŠ¶æ€
U->>CS : å‘é€æ¶ˆæ¯
CS->>AS : è·å–å½“å‰æ™ºèƒ½ä½“é…ç½®
AS-->>CS : è¿”å›APIé…ç½®
CS->>AI : è½¬å‘è¯·æ±‚
AI-->>CS : è¿”å›å“åº”
CS-->>U : æµå¼è¿”å›æ¶ˆæ¯
```

**Diagram sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L97-L123)

## å‰ç«¯ç»„ä»¶æ¶æ„

### ç»„ä»¶å±‚æ¬¡ç»“æ„

```mermaid
graph TD
A[ChatApp] --> B[Header]
A --> C[ChatContainer]
A --> D[Footer]
B --> E[AgentSelector]
B --> F[ThemeToggle]
B --> G[UserProfile]
C --> M[MessageList]
C --> N[MessageInput]
E --> I[AgentDropdown]
E --> J[AgentStatus]
F --> K[ThemeButton]
F --> L[AutoModeToggle]
M --> O[MessageItem]
O --> P[UserMessage]
O --> Q[AssistantMessage]
style E fill:#bbdefb
style I fill:#c8e6c9
style F fill:#fff3e0
style K fill:#f3e5f5
```

**Diagram sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L125-L157)

### æ ¸å¿ƒç»„ä»¶è®¾è®¡

#### AgentSelector ç»„ä»¶

```typescript
interface Agent {
  id: string;
  name: string;
  description: string;
  avatar?: string;
  model: string;
  status: 'active' | 'inactive' | 'error';
  capabilities: string[];
}

interface AgentSelectorProps {
  agents: Agent[];
  currentAgent: Agent;
  onAgentChange: (agent: Agent) => void;
  loading?: boolean;
}
```

**Section sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L159-L187)

#### AgentDropdown ç»„ä»¶

```typescript
interface AgentDropdownProps {
  agents: Agent[];
  selectedAgent: Agent;
  onSelect: (agent: Agent) => void;
  open: boolean;
  onToggle: () => void;
}
```

**Section sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L189-L200)

#### ThemeToggle ç»„ä»¶

```typescript
interface ThemeToggleProps {
  currentTheme: 'light' | 'dark';
  onThemeChange: (theme: 'light' | 'dark') => void;
  autoMode: boolean;
  onAutoModeToggle: () => void;
}

interface ThemeConfig {
  name: string;
  icon: string;
  colors: {
    primary: string;
    background: string;
    surface: string;
    text: string;
    border: string;
    accent: string;
  };
}
```

**Section sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L202-L218)

#### çŠ¶æ€ç®¡ç†æ¥å£

```typescript
interface ChatState {
  currentAgent: Agent | null;
  availableAgents: Agent[];
  messages: Message[];
  loading: boolean;
  error: string | null;
  theme: 'light' | 'dark';
}

interface AgentState {
  agents: Agent[];
  currentAgentId: string | null;
  loading: boolean;
  error: string | null;
}

interface ThemeState {
  currentTheme: 'light' | 'dark';
  isAutoMode: boolean;
  userPreference: 'light' | 'dark' | 'auto';
}
```

**Section sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L220-L233)

## åç«¯æœåŠ¡è®¾è®¡

### æ™ºèƒ½ä½“é…ç½®ç®¡ç†

#### é…ç½®æ–‡ä»¶ç»“æ„

```typescript
interface AgentConfig {
  id: string;
  name: string;
  description: string;
  endpoint: string;
  apiKey: string;
  model: string;
  maxTokens?: number;
  temperature?: number;
  systemPrompt?: string;
  capabilities: string[];
  rateLimit?: {
    requestsPerMinute: number;
    tokensPerMinute: number;
  };
  provider: 'fastgpt' | 'openai' | 'anthropic' | 'custom';
  isActive: boolean;
  features: {
    supportsChatId: boolean;
    supportsStream: boolean;
    supportsDetail: boolean;
    supportsFiles: boolean;
    supportsImages: boolean;
    streamingConfig: {
      enabled: boolean;
      endpoint: 'same' | 'different'; // æ˜¯å¦ä½¿ç”¨ç›¸åŒç«¯ç‚¹
      statusEvents: boolean; // æ˜¯å¦æ”¯æŒçŠ¶æ€äº‹ä»¶
      flowNodeStatus: boolean; // æ˜¯å¦æ”¯æŒæµç¨‹èŠ‚ç‚¹çŠ¶æ€
    };
  };
  createdAt: string;
  updatedAt: string;
}
```

**Section sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L191-L233)

#### é…ç½®æ–‡ä»¶ç¤ºä¾‹ (agents.json)

```json
{
  "agents": [
    {
      "id": "fastgpt-assistant",
      "name": "FastGPT æ™ºèƒ½åŠ©æ‰‹",
      "description": "åŸºäº FastGPT çš„çŸ¥è¯†åº“é—®ç­”åŠ©æ‰‹",
      "endpoint": "http://localhost:3000/api/v1/chat/completions",
      "apiKey": "fastgpt-xxxxxx",
      "model": "FastAI-4k",
      "maxTokens": 4096,
      "temperature": 0.7,
      "systemPrompt": "ä½ æ˜¯ä¸€ä¸ªåŸºäºçŸ¥è¯†åº“çš„æ™ºèƒ½åŠ©æ‰‹ã€‚",
      "capabilities": ["knowledge_base", "context_memory", "file_upload"],
      "rateLimit": {
        "requestsPerMinute": 60,
        "tokensPerMinute": 40000
      },
      "provider": "fastgpt",
      "isActive": true,
      "features": {
        "supportsChatId": true,
        "supportsStream": true,
        "supportsDetail": true,
        "supportsFiles": true,
        "supportsImages": true,
        "streamingConfig": {
          "enabled": true,
          "endpoint": "same",
          "statusEvents": true,
          "flowNodeStatus": true
        }
      },
      "createdAt": "2024-01-01T00:00:00Z",
      "updatedAt": "2024-01-01T00:00:00Z"
    },
    {
      "id": "gpt-4-assistant",
      "name": "GPT-4 åŠ©æ‰‹",
      "description": "åŸºäº GPT-4 çš„é€šç”¨æ™ºèƒ½åŠ©æ‰‹",
      "endpoint": "https://api.openai.com/v1/chat/completions",
      "apiKey": "sk-xxxxxxxxxx",
      "model": "gpt-4-turbo-preview",
      "maxTokens": 4096,
      "temperature": 0.7,
      "systemPrompt": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚",
      "capabilities": ["text", "analysis", "coding"],
      "rateLimit": {
        "requestsPerMinute": 60,
        "tokensPerMinute": 40000
      },
      "provider": "openai",
      "isActive": true,
      "features": {
        "supportsChatId": false,
        "supportsStream": true,
        "supportsDetail": false,
        "supportsFiles": false,
        "supportsImages": true,
        "streamingConfig": {
          "enabled": true,
          "endpoint": "same",
          "statusEvents": false,
          "flowNodeStatus": false
        }
      },
      "createdAt": "2024-01-01T00:00:00Z",
      "updatedAt": "2024-01-01T00:00:00Z"
    },
    {
      "id": "claude-assistant",
      "name": "Claude åŠ©æ‰‹",
      "description": "åŸºäº Claude çš„æ™ºèƒ½åŠ©æ‰‹",
      "endpoint": "https://api.anthropic.com/v1/messages",
      "apiKey": "sk-ant-xxxxxxxxxx",
      "model": "claude-3-sonnet-20240229",
      "maxTokens": 4096,
      "temperature": 0.7,
      "capabilities": ["text", "analysis", "reasoning"],
      "provider": "anthropic",
      "isActive": true,
      "features": {
        "supportsChatId": false,
        "supportsStream": true,
        "supportsDetail": false,
        "supportsFiles": true,
        "supportsImages": true,
        "streamingConfig": {
          "enabled": true,
          "endpoint": "same",
          "statusEvents": false,
          "flowNodeStatus": false
        }
      },
      "createdAt": "2024-01-01T00:00:00Z",
      "updatedAt": "2024-01-01T00:00:00Z"
    }
  ]
}
```

**Section sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L235-L368)

### API ç«¯ç‚¹è®¾è®¡

#### æ™ºèƒ½ä½“ç®¡ç† API

| ç«¯ç‚¹ | æ–¹æ³• | æè¿° | å‚æ•° |
|------|------|------|------|
| `/api/agents` | GET | è·å–å¯ç”¨æ™ºèƒ½ä½“åˆ—è¡¨ | - |
| `/api/agents/:id` | GET | è·å–ç‰¹å®šæ™ºèƒ½ä½“ä¿¡æ¯ | id: æ™ºèƒ½ä½“ID |
| `/api/agents/:id/status` | GET | æ£€æŸ¥æ™ºèƒ½ä½“çŠ¶æ€ | id: æ™ºèƒ½ä½“ID |

#### èŠå¤©ä»£ç† API

| ç«¯ç‚¹ | æ–¹æ³• | æè¿° | å‚æ•° |
|------|------|------|------|
| `/api/chat/completions` | POST | å‘é€èŠå¤©è¯·æ±‚ï¼ˆæ”¯æŒæµå¼å’Œéæµå¼ï¼‰ | agentId, messages, stream, options |

**Section sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L369-L421)

### æœåŠ¡å±‚æ¶æ„

#### AgentConfigService

```typescript
class AgentConfigService {
  private configPath: string;
  private agents: Map<string, AgentConfig>;

  async loadAgents(): Promise<AgentConfig[]>;
  async getAgent(id: string): Promise<AgentConfig | null>;
  async updateAgent(id: string, config: Partial<AgentConfig>): Promise<void>;
  async validateAgent(config: AgentConfig): Promise<boolean>;
  async checkAgentHealth(id: string): Promise<boolean>;
}
```

**Section sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L369-L421)

#### ChatProxyService

```typescript
interface StreamStatus {
  type: 'flowNodeStatus' | 'progress' | 'error' | 'complete';
  status: 'running' | 'completed' | 'error';
  moduleName?: string;
  progress?: number;
  error?: string;
}
class ChatProxyService {
  private agentService: AgentConfigService;
  private httpClient: AxiosInstance;

  async sendMessage(
    agentId: string,
    messages: ChatMessage[],
    options?: ChatOptions
  ): Promise<ChatResponse> {
    const config = await this.agentService.getAgent(agentId);
    const stream = options?.stream ?? config.features.streamingConfig.enabled;
    
    const request = await this.transformRequest(config, messages, stream, options);
    
    const response = await this.httpClient.post(config.endpoint, request, {
      headers: this.buildHeaders(config)
    });
    
    return this.transformResponse(config, response.data);
  }

  async sendStreamMessage(
    agentId: string,
    messages: ChatMessage[],
    onChunk: (chunk: string) => void,
    onStatusChange?: (status: StreamStatus) => void,
    options?: ChatOptions
  ): Promise<ReadableStream>;

  private async transformRequest(
    config: AgentConfig,
    messages: ChatMessage[],
    stream: boolean,
    options?: ChatOptions
  ): Promise<any>;

  private async transformResponse(
    config: AgentConfig,
    response: any
  ): Promise<ChatResponse>;
}
```

**Section sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L369-L421)

## ç”¨æˆ·ç•Œé¢è®¾è®¡

### ä¸»é¢˜è®¾è®¡ç³»ç»Ÿ

#### é¢œè‰²æ–¹æ¡ˆ

##### ç™½å¤©ä¸»é¢˜ (Light Theme)

```css
:root[data-theme="light"] {
  /* èƒŒæ™¯è‰² */
  --bg-primary: #ffffff;
  --bg-secondary: #f8fafc;
  --bg-tertiary: #f1f5f9;
  --bg-overlay: rgba(255, 255, 255, 0.95);
  
  /* æ–‡æœ¬é¢œè‰² */
  --text-primary: #1e293b;
  --text-secondary: #475569;
  --text-tertiary: #64748b;
  --text-inverse: #ffffff;
  
  /* è¾¹æ¡†é¢œè‰² */
  --border-primary: #e2e8f0;
  --border-secondary: #cbd5e1;
  --border-focus: #3b82f6;
  
  /* çªå‡ºé¢œè‰² */
  --accent-primary: #3b82f6;
  --accent-secondary: #1d4ed8;
  --accent-success: #10b981;
  --accent-warning: #f59e0b;
  --accent-error: #ef4444;
  
  /* é˜´å½± */
  --shadow-sm: 0 1px 2px 0 rgba(0, 0, 0, 0.05);
  --shadow-md: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
  --shadow-lg: 0 10px 15px -3px rgba(0, 0, 0, 0.1);
}
```

##### å¤œæ™šä¸»é¢˜ (Dark Theme)

```css
:root[data-theme="dark"] {
  /* èƒŒæ™¯è‰² */
  --bg-primary: #0f172a;
  --bg-secondary: #1e293b;
  --bg-tertiary: #334155;
  --bg-overlay: rgba(15, 23, 42, 0.95);
  
  /* æ–‡æœ¬é¢œè‰² */
  --text-primary: #f8fafc;
  --text-secondary: #e2e8f0;
  --text-tertiary: #cbd5e1;
  --text-inverse: #1e293b;
  
  /* è¾¹æ¡†é¢œè‰² */
  --border-primary: #475569;
  --border-secondary: #64748b;
  --border-focus: #60a5fa;
  
  /* çªå‡ºé¢œè‰² */
  --accent-primary: #60a5fa;
  --accent-secondary: #3b82f6;
  --accent-success: #34d399;
  --accent-warning: #fbbf24;
  --accent-error: #f87171;
  
  /* é˜´å½± */
  --shadow-sm: 0 1px 2px 0 rgba(0, 0, 0, 0.3);
  --shadow-md: 0 4px 6px -1px rgba(0, 0, 0, 0.4);
  --shadow-lg: 0 10px 15px -3px rgba(0, 0, 0, 0.4);
}
```

**Section sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L423-L505)

#### ä¸»é¢˜åˆ‡æ¢æœºåˆ¶

```mermaid
stateDiagram-v2
[âˆ—] --> åˆå§‹åŒ–
åˆå§‹åŒ– --> æ£€æµ‹ç”¨æˆ·åå¥½
æ£€æµ‹ç”¨æˆ·åå¥½ --> ç™½å¤©æ¨¡å¼ : ç”¨æˆ·è®¾ç½®ä¸ºç™½å¤©
æ£€æµ‹ç”¨æˆ·åå¥½ --> å¤œæ™šæ¨¡å¼ : ç”¨æˆ·è®¾ç½®ä¸ºå¤œæ™š
æ£€æµ‹ç”¨æˆ·åå¥½ --> è‡ªåŠ¨æ¨¡å¼ : ç³»ç»Ÿé»˜è®¤æˆ–è‡ªåŠ¨
è‡ªåŠ¨æ¨¡å¼ --> æ£€æµ‹ç³»ç»Ÿæ—¶é—´
æ£€æµ‹ç³»ç»Ÿæ—¶é—´ --> ç™½å¤©æ¨¡å¼ : 6 : 00-18 : 00
æ£€æµ‹ç³»ç»Ÿæ—¶é—´ --> å¤œæ™šæ¨¡å¼ : 18 : 00-6 : 00
ç™½å¤©æ¨¡å¼ --> ç”¨æˆ·æ‰‹åŠ¨åˆ‡æ¢ : ç‚¹å‡»ä¸»é¢˜æŒ‰é’®
å¤œæ™šæ¨¡å¼ --> ç”¨æˆ·æ‰‹åŠ¨åˆ‡æ¢ : ç‚¹å‡»ä¸»é¢˜æŒ‰é’®
ç”¨æˆ·æ‰‹åŠ¨åˆ‡æ¢ --> ç™½å¤©æ¨¡å¼
ç”¨æˆ·æ‰‹åŠ¨åˆ‡æ¢ --> å¤œæ™šæ¨¡å¼
ç”¨æˆ·æ‰‹åŠ¨åˆ‡æ¢ --> è‡ªåŠ¨æ¨¡å¼
```

**Diagram sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L507-L535)

### ä¸»é¢˜ç»„ä»¶è®¾è®¡

#### ThemeProvider ç»„ä»¶

```typescript
interface ThemeProviderProps {
  children: React.ReactNode;
  defaultTheme?: 'light' | 'dark' | 'auto';
  storageKey?: string;
}

const ThemeProvider: React.FC<ThemeProviderProps> = ({
  children,
  defaultTheme = 'auto',
  storageKey = 'chat-theme'
}) => {
  const [theme, setTheme] = useState<'light' | 'dark'>('light');
  const [userPreference, setUserPreference] = useState<'light' | 'dark' | 'auto'>(defaultTheme);
  
  useEffect(() => {
    const savedTheme = localStorage.getItem(storageKey);
    if (savedTheme) {
      setUserPreference(savedTheme as 'light' | 'dark' | 'auto');
    }
    
    updateTheme();
  }, [userPreference]);
  
  const updateTheme = () => {
    if (userPreference === 'auto') {
      const hour = new Date().getHours();
      setTheme(hour >= 6 && hour < 18 ? 'light' : 'dark');
    } else {
      setTheme(userPreference);
    }
  };
  
  const toggleTheme = () => {
    const themes = ['light', 'dark', 'auto'] as const;
    const currentIndex = themes.indexOf(userPreference);
    const nextTheme = themes[(currentIndex + 1) % themes.length];
    setUserPreference(nextTheme);
    localStorage.setItem(storageKey, nextTheme);
  };
  
  useEffect(() => {
    document.documentElement.setAttribute('data-theme', theme);
  }, [theme]);
  
  return (
    <ThemeContext.Provider value={{ theme, userPreference, toggleTheme, updateTheme }}>
      {children}
    </ThemeContext.Provider>
  );
};
```

**Section sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L537-L587)

#### ThemeToggleButton ç»„ä»¶

```typescript
interface ThemeToggleButtonProps {
  size?: 'sm' | 'md' | 'lg';
  showLabel?: boolean;
  variant?: 'icon' | 'button';
}

const ThemeToggleButton: React.FC<ThemeToggleButtonProps> = ({
  size = 'md',
  showLabel = false,
  variant = 'icon'
}) => {
  const { theme, userPreference, toggleTheme } = useTheme();
  
  const getIcon = () => {
    switch (userPreference) {
      case 'light': return <SunIcon />;
      case 'dark': return <MoonIcon />;
      case 'auto': return <AutoIcon />;
    }
  };
  
  const getLabel = () => {
    switch (userPreference) {
      case 'light': return 'ç™½å¤©æ¨¡å¼';
      case 'dark': return 'å¤œæ™šæ¨¡å¼';
      case 'auto': return 'è‡ªåŠ¨æ¨¡å¼';
    }
  };
  
  return (
    <button
      onClick={toggleTheme}
      className={cn(
        'flex items-center gap-2 rounded-lg transition-colors',
        'hover:bg-gray-100 dark:hover:bg-gray-800',
        'focus:outline-none focus:ring-2 focus:ring-blue-500',
        variant === 'icon' ? 'p-2' : 'px-3 py-2',
        size === 'sm' && 'text-sm',
        size === 'lg' && 'text-lg'
      )}
      title={getLabel()}
    >
      {getIcon()}
      {showLabel && <span>{getLabel()}</span>}
    </button>
  );
};
```

**Section sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L589-L636)

### æ™ºèƒ½ä½“é€‰æ‹©å™¨ç•Œé¢

#### ä¸‹æ‹‰é€‰æ‹©å™¨è®¾è®¡

```mermaid
graph LR
A[å½“å‰æ™ºèƒ½ä½“æ˜¾ç¤º] --> B{ç‚¹å‡»å±•å¼€}
B --> C[æ™ºèƒ½ä½“åˆ—è¡¨]
C --> D[æ™ºèƒ½ä½“é¡¹]
D --> E[å¤´åƒ]
D --> F[åç§°]
D --> G[æè¿°]
D --> H[çŠ¶æ€æŒ‡ç¤ºå™¨]
D --> I[èƒ½åŠ›æ ‡ç­¾]
```

**Diagram sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L638-L652)

#### çŠ¶æ€æŒ‡ç¤ºå™¨å¢å¼º

| çŠ¶æ€ | é¢œè‰² | å›¾æ ‡ | æè¿° | é€‚ç”¨äº |
|------|------|------|------|----------|
| active | ç»¿è‰² | â— | æ™ºèƒ½ä½“å¯ç”¨ | æ‰€æœ‰æä¾›å•† |
| inactive | ç°è‰² | â—‹ | æ™ºèƒ½ä½“ä¸å¯ç”¨ | æ‰€æœ‰æä¾›å•† |
| error | çº¢è‰² | âš  | æ™ºèƒ½ä½“é”™è¯¯ | æ‰€æœ‰æä¾›å•† |
| loading | è“è‰² | âŸ³ | æ£€æŸ¥çŠ¶æ€ä¸­ | æ‰€æœ‰æä¾›å•† |
| knowledge_ready | æ©™è‰² | ğŸ“š | çŸ¥è¯†åº“å°±ç»ª | FastGPT |
| context_active | ç´«è‰² | ğŸ’¬ | ä¸Šä¸‹æ–‡æ¿€æ´» | FastGPT |

**Section sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L654-L669)

#### Provider æ ‡è¯†è®¾è®¡

```typescript
interface ProviderBadge {
  provider: 'fastgpt' | 'openai' | 'anthropic' | 'custom';
  icon: string;
  color: string;
  label: string;
}

const providerBadges: Record<string, ProviderBadge> = {
  fastgpt: {
    provider: 'fastgpt',
    icon: 'ğŸš€',
    color: '#10b981',
    label: 'FastGPT'
  },
  openai: {
    provider: 'openai', 
    icon: 'ğŸ¤–',
    color: '#3b82f6',
    label: 'OpenAI'
  },
  anthropic: {
    provider: 'anthropic',
    icon: 'ğŸ¨',
    color: '#8b5cf6', 
    label: 'Claude'
  },
  custom: {
    provider: 'custom',
    icon: 'âš™ï¸',
    color: '#6b7280',
    label: 'è‡ªå®šä¹‰'
  }
};
```

**Section sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L671-L705)

#### FastGPT ç‰¹æœ‰ç•Œé¢å…ƒç´ 

```typescript
// FastGPT æ™ºèƒ½ä½“é€‰æ‹©å™¨çš„ç‰¹æœ‰æ˜¾ç¤º
const FastGPTAgentCard: React.FC<{ agent: AgentConfig }> = ({ agent }) => {
  const [contextStatus, setContextStatus] = useState<'active' | 'inactive'>('inactive');
  const [knowledgeStatus, setKnowledgeStatus] = useState<'ready' | 'loading'>('loading');
  
  useEffect(() => {
    // æ£€æŸ¥ FastGPT ç‰¹æœ‰çŠ¶æ€
    checkFastGPTStatus();
  }, [agent.id]);
  
  const checkFastGPTStatus = async () => {
    try {
      const response = await fetch(`${agent.endpoint}/status`, {
        headers: { 'Authorization': `Bearer ${agent.apiKey}` }
      });
      const status = await response.json();
      setContextStatus(status.contextActive ? 'active' : 'inactive');
      setKnowledgeStatus(status.knowledgeReady ? 'ready' : 'loading');
    } catch (error) {
      console.warn('Failed to check FastGPT status:', error);
    }
  };
  
  return (
    <div className="agent-card fastgpt-card">
      <div className="agent-header">
        <div className="agent-avatar">
          <span className="provider-icon">ğŸš€</span>
        </div>
        <div className="agent-info">
          <h3 className="agent-name">{agent.name}</h3>
          <p className="agent-description">{agent.description}</p>
        </div>
        <div className="agent-status">
          <StatusIndicator status="active" />
        </div>
      </div>
      
      <div className="agent-features">
        <div className="feature-badges">
          {agent.capabilities.map(cap => (
            <span key={cap} className="capability-badge">{cap}</span>
          ))}
        </div>
        
        {/* FastGPT ç‰¹æœ‰çŠ¶æ€ */}
        <div className="fastgpt-status">
          <div className={`status-item ${contextStatus}`}>
            <span className="status-icon">ğŸ’¬</span>
            <span className="status-text">ä¸Šä¸‹æ–‡: {contextStatus === 'active' ? 'æ¿€æ´»' : 'æœªæ¿€æ´»'}</span>
          </div>
          <div className={`status-item ${knowledgeStatus}`}>
            <span className="status-icon">ğŸ“š</span>
            <span className="status-text">çŸ¥è¯†åº“: {knowledgeStatus === 'ready' ? 'å°±ç»ª' : 'åŠ è½½ä¸­'}</span>
          </div>
        </div>
      </div>
      
      <div className="agent-model">
        <span className="model-badge">{agent.model}</span>
        <span className="provider-badge fastgpt">FastGPT</span>
      </div>
    </div>
  );
};
```

**Section sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L707-L769)

### èŠå¤©ç•Œé¢å¢å¼º

#### FastGPT ç‰¹æœ‰æ¶ˆæ¯æ˜¾ç¤º

```typescript
// æ˜¾ç¤º FastGPT ç‰¹æœ‰çš„è¯¦ç»†å“åº”ä¿¡æ¯
const FastGPTMessageDisplay: React.FC<{ message: DetailedMessage }> = ({ message }) => {
  const [showDetails, setShowDetails] = useState(false);
  
  return (
    <div className="message assistant fastgpt-message">
      <div className="message-header">
        <div className="agent-info">
          <span className="agent-icon">ğŸš€</span>
          <span className="agent-name">FastGPT</span>
          <span className="model-name">{message.metadata?.model}</span>
        </div>
        <div className="message-actions">
          <button 
            onClick={() => setShowDetails(!showDetails)}
            className="details-toggle"
          >
            {showDetails ? 'éšè—è¯¦æƒ…' : 'æŸ¥çœ‹è¯¦æƒ…'}
          </button>
        </div>
      </div>
      
      <div className="message-content">
        {message.content}
      </div>
      
      {showDetails && message.responseData && (
        <div className="fastgpt-details">
          <h4>æ‰§è¡Œè¯¦æƒ…</h4>
          {message.responseData.map((module, index) => (
            <div key={index} className="module-info">
              <div className="module-header">
```

**Section sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L771-L812)

#### æ¶ˆæ¯æ¥æºæ ‡è¯†

```typescript
interface AgentSwitchNotification {
  type: 'agent_switch';
  fromAgent: Agent;
  toAgent: Agent;
  timestamp: Date;
  message: string;
}
```

**Section sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L813-L844)

#### ChatSession æ¥å£

```typescript
interface ChatSession {
  id: string;
  title: string;
  agentId: string;
  messages: Message[];
  createdAt: Date;
  updatedAt: Date;
  metadata?: {
    totalTokens: number;
    messageCount: number;
  };
}
```

**Section sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L874-L893)

### çŠ¶æ€æŒä¹…åŒ–

#### æœ¬åœ°å­˜å‚¨ç­–ç•¥

```typescript
interface ChatStorage {
  currentSession: ChatSession | null;
  recentAgents: Agent[];
  userPreferences: {
    defaultAgentId?: string;
    theme: 'light' | 'dark' | 'auto';
    streamingEnabled: boolean;
    autoThemeSchedule: {
      enabled: boolean;
      lightModeStart: string; // "06:00"
      darkModeStart: string;  // "18:00"
    };
  };
}

class ThemeManager {
  private static readonly STORAGE_KEY = 'chat-theme-preferences';
  
  static saveThemePreference(preference: 'light' | 'dark' | 'auto'): void {
    const storage = this.getStorage();
    storage.userPreferences.theme = preference;
    localStorage.setItem(this.STORAGE_KEY, JSON.stringify(storage));
  }
  
  static getThemePreference(): 'light' | 'dark' | 'auto' {
    const storage = this.getStorage();
    return storage.userPreferences?.theme || 'auto';
  }
  
  static getCurrentTheme(): 'light' | 'dark' {
    const preference = this.getThemePreference();
    
    if (preference === 'auto') {
      const hour = new Date().getHours();
      const storage = this.getStorage();
      const schedule = storage.userPreferences?.autoThemeSchedule;
      
      if (schedule?.enabled) {
        const lightStart = parseInt(schedule.lightModeStart.split(':')[0]);
        const darkStart = parseInt(schedule.darkModeStart.split(':')[0]);
        return hour >= lightStart && hour < darkStart ? 'light' : 'dark';
      }
      
      return hour >= 6 && hour < 18 ? 'light' : 'dark';
    }
    
    return preference;
  }
  
  private static getStorage(): ChatStorage {
    const stored = localStorage.getItem(this.STORAGE_KEY);
    return stored ? JSON.parse(stored) : {
      currentSession: null,
      recentAgents: [],
      userPreferences: {
        theme: 'auto',
        streamingEnabled: true,
        autoThemeSchedule: {
          enabled: true,
          lightModeStart: '06:00',
          darkModeStart: '18:00'
        }
      }
    };
  }
}
```

**Section sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L895-L1132)

## APIé›†æˆè®¾è®¡

### ç»Ÿä¸€é€‚é…å™¨æ¨¡å¼

```typescript
interface AIProvider {
  name: string;
  transformRequest(messages: Message[], config: AgentConfig): any;
  transformResponse(response: any): Message;
  transformStreamResponse(chunk: any): string;
  validateConfig(config: AgentConfig): boolean;
}

// FastGPT æä¾›å•†é€‚é…å™¨
class FastGPTProvider implements AIProvider {
  name = 'FastGPT';
  
  transformRequest(messages: Message[], config: AgentConfig, stream: boolean = false) {
    return {
      chatId: this.generateChatId(),
      stream: stream && config.features.streamingConfig.enabled,
      detail: config.features.supportsDetail,
      variables: {},
      messages: messages.map(msg => ({
        role: msg.role,
        content: msg.content
      }))
    };
  }
  
  transformResponse(response: any): Message {
    return {
      id: response.id || generateId(),
      role: 'assistant',
      content: response.choices[0].message.content,
      timestamp: new Date(),
      metadata: {
        model: response.model,
        tokens: response.usage?.total_tokens,
        responseData: response.responseData // FastGPT ç‰¹æœ‰çš„è¯¦ç»†ä¿¡æ¯
      }
    };
  }
  
  transformStreamResponse(chunk: any): string {
    if (chunk.choices && chunk.choices[0]?.delta?.content) {
      return chunk.choices[0].delta.content;
    }
    return '';
  }
  
  validateConfig(config: AgentConfig): boolean {
    return (
      config.endpoint.includes('fastgpt') &&
      config.apiKey.startsWith('fastgpt-') &&
      config.provider === 'fastgpt'
    );
  }
  
  private generateChatId(): string {
    return `fastgpt_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  }
  
  // FastGPT ç‰¹æœ‰åŠŸèƒ½æ”¯æŒ
  async uploadFile(file: File, config: AgentConfig): Promise<string> {
    const formData = new FormData();
    formData.append('file', file);
    
    const response = await fetch(`${config.endpoint.replace('/chat/completions', '/upload')}`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${config.apiKey}`
      },
      body: formData
    });
    
    const result = await response.json();
    return result.url;
  }
}

class OpenAIProvider implements AIProvider {
  name = 'OpenAI';
  
  transformRequest(messages: Message[], config: AgentConfig, stream: boolean = false) {
    return {
      model: config.model,
      messages: messages.map(msg => ({
        role: msg.role,
        content: msg.content
      })),
      max_tokens: config.maxTokens,
      temperature: config.temperature,
      stream: stream && config.features.streamingConfig.enabled
    };
  }
  
  transformResponse(response: any): Message {
    return {
      id: generateId(),
      role: 'assistant',
      content: response.choices[0].message.content,
      timestamp: new Date(),
      metadata: {
        model: response.model,
        tokens: response.usage?.total_tokens
      }
    };
  }
  
  transformStreamResponse(chunk: any): string {
    if (chunk.choices && chunk.choices[0]?.delta?.content) {
      return chunk.choices[0].delta.content;
    }
    return '';
  }
  
  validateConfig(config: AgentConfig): boolean {
    return (
      config.endpoint.includes('openai.com') &&
      config.apiKey.startsWith('sk-') &&
      config.provider === 'openai'
    );
  }
}

class AnthropicProvider implements AIProvider {
  name = 'Anthropic';
  
  transformRequest(messages: Message[], config: AgentConfig, stream: boolean = false) {
    return {
      model: config.model,
      max_tokens: config.maxTokens,
      messages: messages.map(msg => ({
        role: msg.role,
        content: msg.content
      })),
      stream: stream && config.features.streamingConfig.enabled
    };
  }
  
  transformResponse(response: any): Message {
    return {
      id: generateId(),
      role: 'assistant',
      content: response.content[0].text,
      timestamp: new Date(),
      metadata: {
        model: response.model,
        tokens: response.usage?.output_tokens
      }
    };
  }
  
  transformStreamResponse(chunk: any): string {
    if (chunk.type === 'content_block_delta') {
      return chunk.delta.text || '';
    }
    return '';
  }
  
  validateConfig(config: AgentConfig): boolean {
    return (
      config.endpoint.includes('anthropic.com') &&
      config.apiKey.startsWith('sk-ant-') &&
      config.provider === 'anthropic'
    );
  }
}
```

**Section sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L1133-L1428)

## è®¿é—®æ§åˆ¶

```typescript
interface UserPermissions {
  allowedAgents: string[];
  rateLimit: {
    requestsPerHour: number;
    maxConcurrentRequests: number;
  };
  features: {
    canSwitchAgents: boolean;
    canViewAgentDetails: boolean;
  };
}

class AccessController {
  async checkAgentAccess(userId: string, agentId: string): Promise<boolean> {
    const permissions = await this.getUserPermissions(userId);
    return permissions.allowedAgents.includes(agentId);
  }

  async checkRateLimit(userId: string): Promise<boolean> {
    const usage = await this.getUserUsage(userId);
    const permissions = await this.getUserPermissions(userId);
    return usage.requestsInLastHour < permissions.rateLimit.requestsPerHour;
  }
}
```

**Section sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L2089-L2148)

## ç›‘æ§å’Œæ—¥å¿—

### ä½¿ç”¨æƒ…å†µè·Ÿè¸ª

```typescript
interface AgentUsageMetrics {
  agentId: string;
  requestCount: number;
  totalTokens: number;
  averageResponseTime: number;
  errorRate: number;
  lastUsed: Date;
}

class UsageTracker {
  async trackRequest(agentId: string, tokens: number, responseTime: number): Promise<void> {
    await this.database.agents_usage.upsert({
      agent_id: agentId,
      date: new Date().toDateString(),
      request_count: { increment: 1 },
      total_tokens: { increment: tokens },
      total_response_time: { increment: responseTime }
    });
  }

  async getAgentMetrics(agentId: string, period: 'day' | 'week' | 'month'): Promise<AgentUsageMetrics> {
    // å®ç°æŒ‡æ ‡æŸ¥è¯¢é€»è¾‘
  }
}
```

**Section sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L2089-L2148)

### é”™è¯¯æ—¥å¿—

```typescript
class ErrorLogger {
  async logError(error: APIError, context: any): Promise<void> {
    const logEntry = {
      timestamp: new Date(),
      level: 'error',
      agentId: error.agentId,
      errorCode: error.code,
      message: error.message,
      context: JSON.stringify(context),
      stackTrace: error.stack
    };

    await this.writeLog(logEntry);
    
    if (this.isCriticalError(error)) {
      await this.sendAlert(logEntry);
    }
  }

  private isCriticalError(error: APIError): boolean {
    const criticalCodes = ['AGENT_UNAVAILABLE', 'INVALID_API_KEY', 'QUOTA_EXCEEDED'];
    return criticalCodes.includes(error.code);
  }
}
```

**Section sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L2149-L2176)

## å®ç°ç»†èŠ‚

### æ™ºèƒ½ä½“åˆ‡æ¢æµç¨‹

```mermaid
stateDiagram-v2
[*] --> åˆå§‹åŒ–
åˆå§‹åŒ– --> åŠ è½½æ™ºèƒ½ä½“åˆ—è¡¨
åŠ è½½æ™ºèƒ½ä½“åˆ—è¡¨ --> æ˜¾ç¤ºé»˜è®¤æ™ºèƒ½ä½“
æ˜¾ç¤ºé»˜è®¤æ™ºèƒ½ä½“ --> ç­‰å¾…ç”¨æˆ·æ“ä½œ
ç­‰å¾…ç”¨æˆ·æ“ä½œ --> ç”¨æˆ·é€‰æ‹©æ™ºèƒ½ä½“ : ç‚¹å‡»ä¸‹æ‹‰èœå•
ç”¨æˆ·é€‰æ‹©æ™ºèƒ½ä½“ --> éªŒè¯æ™ºèƒ½ä½“çŠ¶æ€
éªŒè¯æ™ºèƒ½ä½“çŠ¶æ€ --> åˆ‡æ¢æˆåŠŸ : éªŒè¯é€šè¿‡
éªŒè¯æ™ºèƒ½ä½“çŠ¶æ€ --> æ˜¾ç¤ºé”™è¯¯ : éªŒè¯å¤±è´¥
æ˜¾ç¤ºé”™è¯¯ --> ç­‰å¾…ç”¨æˆ·æ“ä½œ
åˆ‡æ¢æˆåŠŸ --> æ›´æ–°ç•Œé¢çŠ¶æ€
æ›´æ–°ç•Œé¢çŠ¶æ€ --> ä¿å­˜ç”¨æˆ·åå¥½
ä¿å­˜ç”¨æˆ·åå¥½ --> ç­‰å¾…ç”¨æˆ·æ“ä½œ
```

**Diagram sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L1133-L1194)

### æ¶ˆæ¯è·¯ç”±æœºåˆ¶

```typescript
const ChatInterface: React.FC = () => {
  const [messages, setMessages] = useState<Message[]>([]);
  const [isStreaming, setIsStreaming] = useState(false);
  const [streamStatus, setStreamStatus] = useState<StreamStatus | null>(null);
  const [currentAgent, setCurrentAgent] = useState<AgentConfig | null>(null);
  const messageRouter = new MessageRouter();
  
  const sendMessage = async (content: string) => {
    const userMessage: Message = {
      id: generateId(),
      role: 'user',
      content,
      timestamp: new Date()
    };
    
    setMessages(prev => [...prev, userMessage]);
    setIsStreaming(true);
    setStreamStatus(null);
    
    let assistantContent = '';
    const assistantMessage: Message = {
      id: generateId(),
      role: 'assistant',
      content: '',
      timestamp: new Date(),
      agentId: currentAgent?.id
    };
    
    setMessages(prev => [...prev, assistantMessage]);
    
    try {
      await messageRouter.routeStreamMessage(
        userMessage,
        (chunk: string) => {
          assistantContent += chunk;
          setMessages(prev => 
            prev.map(msg => 
              msg.id === assistantMessage.id 
                ? { ...msg, content: assistantContent }
                : msg
            )
          );
        },
        (status: StreamStatus) => {
          // æ›´æ–°æµå¼çŠ¶æ€
          setStreamStatus(status);
        }
      );
    } catch (error) {
      console.error('Stream error:', error);
    } finally {
      setIsStreaming(false);
      setStreamStatus(null);
    }
  };
  
  return (
    <div className="chat-interface">
      {/* æ™ºèƒ½ä½“é€‰æ‹©å™¨ */}
      <AgentSelector 
        currentAgent={currentAgent}
        onAgentChange={setCurrentAgent}
      />
      
      {/* æ¶ˆæ¯åˆ—è¡¨ */}
      <div className="messages-container">
        {messages.map(message => (
          <MessageComponent key={message.id} message={message} />
        ))}
        
        {/* FastGPT æµå¼çŠ¶æ€æ˜¾ç¤º */}
        <StreamingStatusIndicator 
          isStreaming={isStreaming}
          currentStatus={streamStatus}
          agent={currentAgent}
        />
      </div>
      
      {/* è¾“å…¥æ¡† */}
      <MessageInput 
        onSend={sendMessage}
        disabled={isStreaming}
      />
    </div>
  );
};
```

**Section sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L1429-L1516)

#### FastGPT æµå¼äº‹ä»¶å¤„ç†

```typescript
const ChatContainer = styled.div<{ theme: 'light' | 'dark' }>`
  background: var(--bg-primary);
  color: var(--text-primary);
  border: 1px solid var(--border-primary);
  transition: all 0.3s ease;
  
  /* èŠå¤©æ¶ˆæ¯æ ·å¼ */
  .message-user {
    background: ${props => props.theme === 'light' ? '#3b82f6' : '#60a5fa'};
    color: var(--text-inverse);
    border-radius: 18px 18px 4px 18px;
  }
  
  .message-assistant {
    background: var(--bg-secondary);
    color: var(--text-primary);
    border: 1px solid var(--border-primary);
    border-radius: 18px 18px 18px 4px;
  }
  
  /* æ™ºèƒ½ä½“é€‰æ‹©å™¨æ ·å¼ */
  .agent-selector {
    background: var(--bg-tertiary);
    border: 1px solid var(--border-primary);
    border-radius: 12px;
    
    &:hover {
      border-color: var(--border-focus);
    }
    
    &:focus-within {
      box-shadow: 0 0 0 3px rgba(59, 130, 246, 0.1);
    }
  }
  
  /* ä¸»é¢˜åˆ‡æ¢æŒ‰é’®æ ·å¼ */
  .theme-toggle {
    background: var(--bg-secondary);
    border: 1px solid var(--border-primary);
    border-radius: 8px;
    padding: 8px;
    
    &:hover {
      background: var(--bg-tertiary);
    }
    
    .icon {
      color: var(--text-secondary);
      transition: color 0.2s ease;
    }
  }
`;

#### æ™ºèƒ½ä½“çŠ¶æ€ç¼“å­˜

```typescript
class AgentStatusCache {
  private cache: Map<string, { status: string; timestamp: Date }>;
  private readonly CACHE_TTL = 5 * 60 * 1000; // 5åˆ†é’Ÿ

  async getStatus(agentId: string): Promise<string> {
    const cached = this.cache.get(agentId);
    
    if (cached && Date.now() - cached.timestamp.getTime() < this.CACHE_TTL) {
      return cached.status;
    }

    const status = await this.checkAgentStatus(agentId);
    this.cache.set(agentId, { status, timestamp: new Date() });
    return status;
  }

  private async checkAgentStatus(agentId: string): Promise<string> {
    // å®ç°çŠ¶æ€æ£€æŸ¥é€»è¾‘
    try {
      const config = await this.agentService.getAgent(agentId);
      const response = await fetch(config.endpoint, {
        method: 'OPTIONS',
        timeout: 5000
      });
      return response.ok ? 'active' : 'error';
    } catch {
      return 'error';
    }
  }
}
```

#### é¢„åŠ è½½æœºåˆ¶

```typescript
class AgentPreloader {
  async preloadPopularAgents(): Promise<void> {
    const popularAgents = await this.getPopularAgents();
    
    const preloadPromises = popularAgents.map(async (agent) => {
      try {
        await this.warmupAgent(agent.id);
      } catch (error) {
        console.warn(`Failed to preload agent ${agent.id}:`, error);
      }
    });

    await Promise.allSettled(preloadPromises);
  }

  private async warmupAgent(agentId: string): Promise<void> {
    const testMessage = { role: 'user', content: 'Hello' };
    await this.messageRouter.routeMessage(testMessage);
  }
}
```

**Section sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L1853-L1969)

### é”™è¯¯å¤„ç†æœºåˆ¶

```typescript
interface APIError {
  code: string;
  message: string;
  agentId: string;
  timestamp: Date;
  details?: any;
}

class ErrorHandler {
  static handleAgentError(error: APIError): UserFriendlyError {
    switch (error.code) {
      case 'AGENT_UNAVAILABLE':
        return {
          message: 'æ™ºèƒ½ä½“æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·é€‰æ‹©å…¶ä»–æ™ºèƒ½ä½“',
          suggestion: 'å°è¯•åˆ‡æ¢åˆ°å…¶ä»–å¯ç”¨çš„æ™ºèƒ½ä½“'
        };
      case 'API_QUOTA_EXCEEDED':
        return {
          message: 'æ™ºèƒ½ä½“ä½¿ç”¨é‡å·²è¾¾ä¸Šé™',
          suggestion: 'è¯·ç¨åå†è¯•æˆ–è”ç³»ç®¡ç†å‘˜'
        };
      case 'INVALID_API_KEY':
        return {
          message: 'æ™ºèƒ½ä½“é…ç½®é”™è¯¯',
          suggestion: 'è¯·è”ç³»ç®¡ç†å‘˜æ£€æŸ¥é…ç½®'
        };
      default:
        return {
          message: 'å‘ç”ŸæœªçŸ¥é”™è¯¯',
          suggestion: 'è¯·åˆ·æ–°é¡µé¢é‡è¯•'
        };
    }
  }
}
```

**Section sources**
- [model-switching-feature.md](file://doc/model-switching-feature.md#L1133-L1194)